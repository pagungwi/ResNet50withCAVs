{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0eebbe-e25f-4711-8409-2a673ba215f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bc8f892-8c4a-4c86-bc5e-3bf418c18494",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform_image=None, transform_mask=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform_image = transform_image\n",
    "        self.transform_mask = transform_mask\n",
    "        self.images_dir = os.path.join(root_dir, 'imgs')\n",
    "        self.masks_dir = os.path.join(root_dir, 'masks')\n",
    "        self.image_filenames = os.listdir(self.images_dir)\n",
    "        \n",
    "        self.image_filenames = [name for name in self.image_filenames if not name.startswith(\".ipynb\")]\n",
    "        \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.images_dir, self.image_filenames[idx])\n",
    "        mask_name = os.path.join(self.masks_dir, self.image_filenames[idx].replace('img_', 'mask_').replace('.jpg', '.png'))\n",
    "        \n",
    "        \n",
    "\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        mask = Image.open(mask_name).convert('L')  # Convert to grayscale for single channel mask\n",
    "\n",
    "        if self.transform_image:\n",
    "            image = self.transform_image(image)\n",
    "        if self.transform_mask:\n",
    "            mask = self.transform_mask(mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49b472dd-8a7c-4ad4-b5aa-5014d0a24247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Transforms dataset\n",
    "#transform = transforms.Compose([\n",
    "#    transforms.Resize((256, 256)),  # Resize image\n",
    "#    transforms.ToTensor(),\n",
    "#])\n",
    "\n",
    "# Define Transforms\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40fc6484-8a64-45ed-bf0d-5d45e213484d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines dataset and dataloaders\n",
    "train_dataset = CustomDataset(root_dir='CAVS/Main_Trail/Train', transform_image=transform_image, transform_mask=transform_mask)\n",
    "test_dataset = CustomDataset(root_dir='CAVS/Main_Trail/Test', transform_image=transform_image, transform_mask=transform_mask)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cc9ac15f-6797-4c05-863e-966bcfcaf1b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define ResNet model for semantic segmentation\n",
    "class ResNetSegmentation(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ResNetSegmentation, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)  # Load pre-trained ResNet\n",
    "        \n",
    "          # Remove the fully connected layer and global average pooling\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-2])\n",
    "\n",
    "        # Add 1x1 convolution layer for the final segmentation map\n",
    "        self.conv1x1 = nn.Conv2d(2048, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.conv1x1(x)\n",
    "        x = F.interpolate(x, size=(256, 256), mode='bilinear', align_corners=False)  # Upsample to (256, 256)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75f6f0cc-eee1-44ad-a07c-9e39e910acf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ResNetSegmentation(num_classes=1)  # Assuming you have binary segmentation (1 channel mask)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1ead5a1-52c8-4379-be33-a16b13a995d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross Entropy loss for binary segmentation\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53f4ba41-d9e8-467f-af08-81d24d5ff4b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19, Loss: 0.6931\n",
      "Epoch 1/19, Loss: 0.6931\n",
      "Epoch 2/19, Loss: 0.6931\n",
      "Epoch 3/19, Loss: 0.6931\n",
      "Epoch 4/19, Loss: 0.6931\n",
      "Epoch 5/19, Loss: 0.6931\n",
      "Epoch 6/19, Loss: 0.6931\n",
      "Epoch 7/19, Loss: 0.6931\n",
      "Epoch 8/19, Loss: 0.6931\n",
      "Epoch 9/19, Loss: 0.6931\n",
      "Epoch 10/19, Loss: 0.6931\n",
      "Epoch 11/19, Loss: 0.6931\n",
      "Epoch 12/19, Loss: 0.6931\n",
      "Epoch 13/19, Loss: 0.6931\n",
      "Epoch 14/19, Loss: 0.6931\n",
      "Epoch 15/19, Loss: 0.6931\n",
      "Epoch 16/19, Loss: 0.6931\n",
      "Epoch 17/19, Loss: 0.6931\n",
      "Epoch 18/19, Loss: 0.6931\n",
      "Epoch 19/19, Loss: 0.6931\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, masks in train_dataloader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Ensure output size matches mask size\n",
    "        outputs = torch.sigmoid(outputs)  # Apply sigmoid to output for binary segmentation\n",
    "        outputs = outputs.view(-1,1,256,256)  # Ensure output size matches mask size\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "    print(f'Epoch {epoch}/{num_epochs - 1}, Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c56a8fdb-d0b0-4703-9ddb-4a7c28ddaa3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 1.3324\n"
     ]
    }
   ],
   "source": [
    "# Evaluation loop (example)\n",
    "model.eval()\n",
    "total_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_dataloader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        total_loss += loss.item() * images.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / len(test_dataloader.dataset)\n",
    "    print(f'Average Test Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b593d014-eb9d-480b-bcf5-4891331f1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves model\n",
    "torch.save(model.state_dict(), 'resnet_segmentation_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f75121-1a48-4d5b-a7cf-35414211b122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_kernel",
   "language": "python",
   "name": "torch_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
