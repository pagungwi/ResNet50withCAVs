{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a419bfb6-6a92-4f99-8022-5f463ec3b59c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6775ea44-fb19-4c05-8e4e-3e43b4d55899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "                               \n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "            \n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module): \n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # ResNet layers\n",
    "        self.layer1 = self._make_layers(block, layers[0], out_channels=64, stride=1)\n",
    "        self.layer2 = self._make_layers(block, layers[1], out_channels=128, stride=2)\n",
    "        self.layer3 = self._make_layers(block, layers[2], out_channels=256, stride=2)\n",
    "        self.layer4 = self._make_layers(block, layers[3], out_channels=512, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def _make_layers(self, block, num_residual_blocks, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != out_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * 4, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels * 4)\n",
    "            )\n",
    "        \n",
    "        layers.append(block(self.in_channels, out_channels, identity_downsample, stride))\n",
    "        self.in_channels = out_channels * 4 \n",
    "        \n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "                \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def ResNet500(img_channels=3, num_classes=3):\n",
    "    model = ResNet(block, [3, 4, 6, 3], img_channels, num_classes)\n",
    "    pretrained_model = models.resnet50(pretrained=True)\n",
    "     # Load pre-trained weights, except for the final fully connected layer\n",
    "    pretrained_dict = pretrained_model.state_dict()\n",
    "    model_dict = model.state_dict()\n",
    "\n",
    "    # Filter out the final layer parameters\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and \"fc\" not in k}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "def ResNet101(img_channels=3, num_classes=3):\n",
    "    model = ResNet(block, [3, 4, 23, 3], img_channels, num_classes)\n",
    "    pretrained_model = models.resnet101(pretrained=True)\n",
    "    model.load_state_dict(pretrained_model.state_dict(), strict=False)\n",
    "    return model\n",
    "\n",
    "def ResNet152(img_channels=3, num_classes=3):\n",
    "    model = ResNet(block, [3, 8, 36, 3], img_channels, num_classes)\n",
    "    pretrained_model = models.resnet152(pretrained=True)\n",
    "    model.load_state_dict(pretrained_model.state_dict(), strict=False)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "622fde10-4b21-4dd0-bfab-15a785e637f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform_image=None, transform_mask=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform_image = transform_image\n",
    "        self.transform_mask = transform_mask\n",
    "        self.images_dir = os.path.join(root_dir, 'imgs')\n",
    "        self.masks_dir = os.path.join(root_dir, 'masks')\n",
    "        self.image_filenames = os.listdir(self.images_dir)\n",
    "        self.image_filenames = [name for name in self.image_filenames if not name.startswith(\".ipynb\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.images_dir, self.image_filenames[idx])\n",
    "        mask_name = os.path.join(self.masks_dir, self.image_filenames[idx].replace('img_', 'mask_').replace('.jpg', '.png'))\n",
    "\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        mask = Image.open(mask_name).convert('RGB') \n",
    "\n",
    "        if self.transform_image:\n",
    "            image = self.transform_image(image)\n",
    "        if self.transform_mask:\n",
    "            mask = self.transform_mask(mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65866416-17cc-4e3d-a91c-497cd5308cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Transforms\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8681a124-b26d-4cd9-baf1-13e432148caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines dataset and dataloaders\n",
    "train_dataset = CustomDataset(root_dir='CAVS/Main_Trail/Train', transform_image=transform_image, transform_mask=transform_mask)\n",
    "test_dataset = CustomDataset(root_dir='CAVS/Main_Trail/Test', transform_image=transform_image, transform_mask=transform_mask)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a13f7b8a-d531-4ed3-b336-3baf18932d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "#model = ResNet50(img_channels=3, num_classes=3) \n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = model.to(device)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c58c2f4-ea0c-46d0-9177-6ec34f2a5b50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 20:24:17.825640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13414 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2024-07-13 20:24:17.826280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 14612 MB memory:  -> device: 1, name: Tesla V100-PCIE-16GB, pci bus id: 0000:d8:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7fc650f1-fa9f-4a0e-a643-59c9e5b5b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate IoU\n",
    "def calculate_iou(pred_mask, true_mask, num_classes):\n",
    "    ious = []\n",
    "    pred_mask = pred_mask.view(-1)\n",
    "    true_mask = true_mask.view(-1)\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (pred_mask == cls)\n",
    "        target_inds = (true_mask == cls)\n",
    "        \n",
    "        intersection = (pred_inds[target_inds]).long().sum().item()\n",
    "        union = pred_inds.long().sum().item() + target_inds.long().sum().item() - intersection\n",
    "        \n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # if there is no ground truth, do not include in the mean\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    \n",
    "    return ious\n",
    "\n",
    "def calculate_miou(pred_mask, true_mask, num_classes):\n",
    "    ious = calculate_iou(pred_mask, true_mask, num_classes)\n",
    "    miou = np.nanmean(ious)  # nanmean to ignore NaN values\n",
    "    return miou, ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "abd845eb-752b-4e5f-8833-a8e89dff92be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fae04586-18af-48e4-b59c-b8e3feab744c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x=<__main__.CustomDataset object at 0x7f29ddfc33d0> (of type <class '__main__.CustomDataset'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      2\u001b[0m     train_dataset,\n\u001b[1;32m      3\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/trainers/data_adapters/__init__.py:120\u001b[0m, in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=<__main__.CustomDataset object at 0x7f29ddfc33d0> (of type <class '__main__.CustomDataset'>)"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=20,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7894d930-88f7-4ee2-9446-f7100d39f1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
