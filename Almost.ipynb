{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a419bfb6-6a92-4f99-8022-5f463ec3b59c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-13 19:40:33.808410: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-13 19:40:34.284414: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-13 19:40:34.289130: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-13 19:40:35.086366: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-13 19:40:41.822336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6775ea44-fb19-4c05-8e4e-3e43b4d55899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, identity_downsample=None, stride=1):\n",
    "        super(block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "                               \n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "            \n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module): \n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # ResNet layers\n",
    "        self.layer1 = self._make_layers(block, layers[0], out_channels=64, stride=1)\n",
    "        self.layer2 = self._make_layers(block, layers[1], out_channels=128, stride=2)\n",
    "        self.layer3 = self._make_layers(block, layers[2], out_channels=256, stride=2)\n",
    "        self.layer4 = self._make_layers(block, layers[3], out_channels=512, stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def _make_layers(self, block, num_residual_blocks, out_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != out_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels * 4, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels * 4)\n",
    "            )\n",
    "        \n",
    "        layers.append(block(self.in_channels, out_channels, identity_downsample, stride))\n",
    "        self.in_channels = out_channels * 4 \n",
    "        \n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "                \n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "def ResNet50(img_channels=3, num_classes=3):\n",
    "    model = ResNet(block, [3, 4, 6, 3], img_channels, num_classes)\n",
    "    pretrained_model = models.resnet50(pretrained=True)\n",
    "     # Load pre-trained weights, except for the final fully connected layer\n",
    "    pretrained_dict = pretrained_model.state_dict()\n",
    "    model_dict = model.state_dict()\n",
    "\n",
    "    # Filter out the final layer parameters\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict and \"fc\" not in k}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "def ResNet101(img_channels=3, num_classes=3):\n",
    "    model = ResNet(block, [3, 4, 23, 3], img_channels, num_classes)\n",
    "    pretrained_model = models.resnet101(pretrained=True)\n",
    "    model.load_state_dict(pretrained_model.state_dict(), strict=False)\n",
    "    return model\n",
    "\n",
    "def ResNet152(img_channels=3, num_classes=3):\n",
    "    model = ResNet(block, [3, 8, 36, 3], img_channels, num_classes)\n",
    "    pretrained_model = models.resnet152(pretrained=True)\n",
    "    model.load_state_dict(pretrained_model.state_dict(), strict=False)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "622fde10-4b21-4dd0-bfab-15a785e637f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform_image=None, transform_mask=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.transform_image = transform_image\n",
    "        self.transform_mask = transform_mask\n",
    "        self.images_dir = os.path.join(root_dir, 'imgs')\n",
    "        self.masks_dir = os.path.join(root_dir, 'masks')\n",
    "        self.image_filenames = os.listdir(self.images_dir)\n",
    "        self.image_filenames = [name for name in self.image_filenames if not name.startswith(\".ipynb\")]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.images_dir, self.image_filenames[idx])\n",
    "        mask_name = os.path.join(self.masks_dir, self.image_filenames[idx].replace('img_', 'mask_').replace('.jpg', '.png'))\n",
    "\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        mask = Image.open(mask_name).convert('RGB') \n",
    "\n",
    "        if self.transform_image:\n",
    "            image = self.transform_image(image)\n",
    "        if self.transform_mask:\n",
    "            mask = self.transform_mask(mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65866416-17cc-4e3d-a91c-497cd5308cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Transforms\n",
    "transform_image = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_mask = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8681a124-b26d-4cd9-baf1-13e432148caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defines dataset and dataloaders\n",
    "train_dataset = CustomDataset(root_dir='CAVS/Main_Trail/Train', transform_image=transform_image, transform_mask=transform_mask)\n",
    "test_dataset = CustomDataset(root_dir='CAVS/Main_Trail/Test', transform_image=transform_image, transform_mask=transform_mask)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a13f7b8a-d531-4ed3-b336-3baf18932d2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = ResNet50(img_channels=3, num_classes=3) \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc650f1-fa9f-4a0e-a643-59c9e5b5b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate IoU\n",
    "def calculate_iou(pred_mask, true_mask, num_classes):\n",
    "    ious = []\n",
    "    pred_mask = pred_mask.view(-1)\n",
    "    true_mask = true_mask.view(-1)\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_inds = (pred_mask == cls)\n",
    "        target_inds = (true_mask == cls)\n",
    "        \n",
    "        intersection = (pred_inds[target_inds]).long().sum().item()\n",
    "        union = pred_inds.long().sum().item() + target_inds.long().sum().item() - intersection\n",
    "        \n",
    "        if union == 0:\n",
    "            ious.append(float('nan'))  # if there is no ground truth, do not include in the mean\n",
    "        else:\n",
    "            ious.append(intersection / union)\n",
    "    \n",
    "    return ious\n",
    "\n",
    "def calculate_miou(pred_mask, true_mask, num_classes):\n",
    "    ious = calculate_iou(pred_mask, true_mask, num_classes)\n",
    "    miou = np.nanmean(ious)  # nanmean to ignore NaN values\n",
    "    return miou, ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "823f4e00-d960-404a-801f-043d1c690c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected true_masks to be a 3D tensor, got 4D tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Ensure true_masks is a 3D tensor with class indices\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m true_masks\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected true_masks to be a 3D tensor, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrue_masks\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD tensor.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Assuming outputs from the model are logits and not softmaxed\u001b[39;00m\n\u001b[1;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, true_masks\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Squeeze to remove channel dimension if necessary\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected true_masks to be a 3D tensor, got 4D tensor."
     ]
    }
   ],
   "source": [
    "# Training loop with IoU and mIoU calculation\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_iou = []\n",
    "    total_miou = []\n",
    "\n",
    "    for inputs, true_masks in tqdm(train_dataloader):\n",
    "        inputs, true_masks = inputs.to(device), true_masks.to(device)\n",
    "\n",
    "        # Ensure inputs are 4D tensors with batch dimension\n",
    "       # if inputs.dim() == 3:\n",
    "        #    inputs = inputs.unsqueeze(0)  # Add batch dimension if missing\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Ensure outputs and true_masks have the same batch size\n",
    "        if outputs.shape[0] != true_masks.shape[0]:\n",
    "            raise ValueError(f\"Batch sizes of outputs ({outputs.shape[0]}) and true_masks ({true_masks.shape[0]}) do not match.\")\n",
    "\n",
    "        # Calculate loss\n",
    "        # Ensure true_masks is a 3D tensor with class indices\n",
    "        if true_masks.dim() != 3:\n",
    "            raise ValueError(f\"Expected true_masks to be a 3D tensor, got {true_masks.dim()}D tensor.\")\n",
    "\n",
    "        # Assuming outputs from the model are logits and not softmaxed\n",
    "        loss = criterion(outputs, true_masks.squeeze(1))  # Squeeze to remove channel dimension if necessary\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate IoU and mIoU for training data\n",
    "        _, pred_masks = torch.max(outputs, 1)\n",
    "        for i in range(inputs.size(0)):\n",
    "            iou = calculate_iou(pred_masks[i], true_masks[i], num_classes)\n",
    "            total_iou.append(iou)\n",
    "            miou, _ = calculate_miou(pred_masks[i], true_masks[i], num_classes)\n",
    "            total_miou.append(miou)\n",
    "\n",
    "    avg_miou = np.nanmean(total_miou)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_dataloader)}, Training mIoU: {avg_miou}\")\n",
    "\n",
    "    total_iou = np.array(total_iou)\n",
    "    avg_iou_per_class = np.nanmean(total_iou, axis=0)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training IoU per class: {avg_iou_per_class}\")\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "total_iou = []\n",
    "total_miou = []\n",
    "with torch.no_grad():\n",
    "    for inputs, true_masks in tqdm(test_dataloader):\n",
    "        inputs, true_masks = inputs.to(device), true_masks.to(device)\n",
    "\n",
    "        # Ensure inputs are 4D tensors with batch dimension\n",
    "        #if inputs.dim() == 3:\n",
    "       #     inputs = inputs.unsqueeze(0)  # Add batch dimension if missing\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Ensure outputs and true_masks have the same batch size\n",
    "        if outputs.shape[0] != true_masks.shape[0]:\n",
    "            raise ValueError(f\"Batch sizes of outputs ({outputs.shape[0]}) and true_masks ({true_masks.shape[0]}) do not match.\")\n",
    "\n",
    "        _, pred_masks = torch.max(outputs, 1)\n",
    "\n",
    "        for i in range(inputs.size(0)):\n",
    "            iou = calculate_iou(pred_masks[i], true_masks[i], num_classes)\n",
    "            total_iou.append(iou)\n",
    "            miou, _ = calculate_miou(pred_masks[i], true_masks[i], num_classes)\n",
    "            total_miou.append(miou)\n",
    "\n",
    "avg_miou = np.nanmean(total_miou)\n",
    "print(f\"Test mIoU: {avg_miou}\")\n",
    "\n",
    "total_iou = np.array(total_iou)\n",
    "avg_iou_per_class = np.nanmean(total_iou, axis=0)\n",
    "print(f\"Test IoU per class: {avg_iou_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd845eb-752b-4e5f-8833-a8e89dff92be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
